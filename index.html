<!DOCTYPE html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Business Card Scanner</title>
  <script type="text/javascript" src="vcf.js"></script>
  <script type="text/javascript" src="utils.js"></script>
  <style>
    #enhancerUIContainer {
      display: none;
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: white;
    }

    .dce-video-container {
      width: 100%;
      height: 100%;
    }

    .close-button {
      position: absolute;
      top: 0;
      right: 0;
    }

    .modal {
      display: flex;
      align-items: flex-start;
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      min-width: 250px;
      min-height: 150px;
      border: 1px solid gray;
      border-radius: 5px;
      background: white;
      z-index: 9999;
      padding: 10px;
      visibility: hidden;
    }

    .progress-modal {
      align-items: center;
      text-align: center;
      justify-content: center;
      min-height: 50px;
      max-height: 100px;
    }

    .progress-modal.active {
      visibility: inherit;
    }

    #image {
      max-width: 320px;
      width: 100%;
    }
  </style>
</head>
<html>
<body>
  <h1>Business Card Scanner</h1>
  <div>
    <label>
      Camera:
      <select id="select-camera"></select>
    </label>
  </div>
  <div>
    <label>
      Resolution:
      <select id="select-resolution">
        <option value="640x480">640x480</option>
        <option value="1280x720">1280x720</option>
        <option value="1920x1080" selected>1920x1080</option>
        <option value="3840x2160">3840x2160</option>
      </select>
    </label>
  </div>
  <button onclick="startDetection()">Start Detection</button>
  <div>
    <img id="image"/>
  </div>
  <div id="enhancerUIContainer">
    <div class="dce-video-container"></div>
    <button class="close-button">Close</button>
  </div>
  <div class="modal progress-modal"></div>
  <script src="https://cdn.jsdelivr.net/npm/dynamsoft-capture-vision-bundle@2.6.1000/dist/dcv.bundle.js"></script>
  <script>
    let previousDetectionResults = [];
    let dcvLicense = "DLS2eyJvcmdhbml6YXRpb25JRCI6IjIwMDAwMSJ9";
    let cameraViewContainer = document.getElementById("enhancerUIContainer")
    let router;
    let cameraEnhancer;
    let drawingLayer;
    let processing = false;
    let interval;
    init();
    async function init(){
      showProgress("Loading...");
      Dynamsoft.License.LicenseManager.initLicense(dcvLicense);
      Dynamsoft.Core.CoreModule.loadWasm(["DDN","DBR"]);
      router = await Dynamsoft.CVR.CaptureVisionRouter.createInstance();
      let cameraView = await Dynamsoft.DCE.CameraView.createInstance(cameraViewContainer);
      drawingLayer = cameraView.createDrawingLayer();
      let newStyleId = Dynamsoft.DCE.DrawingStyleManager.createDrawingStyle({
          fillStyle: "rgba(100, 75, 245, 0.3)",
          lineWidth: 5,
          paintMode: "strokeAndFill",
          strokeStyle: "rgba(73, 173, 245, 1)"
      });
      drawingLayer.setDefaultStyle(newStyleId);
      cameraEnhancer = await Dynamsoft.DCE.CameraEnhancer.createInstance(cameraView);
      router.setInput(cameraEnhancer);
      imageEditorView = await Dynamsoft.DCE.ImageEditorView.createInstance(cameraViewContainer);
      editorDrawingLayer = imageEditorView.createDrawingLayer();
      await listCameras();
      document.getElementsByClassName("close-button")[0].addEventListener("click",function(){
        stopDetection();
      })
      hideProgress();
    }

    function showProgress(info) {
      document.getElementsByClassName("progress-modal")[0].classList.add("active");
      document.getElementsByClassName("progress-modal")[0].innerText = info;
    }

    function hideProgress(){
      document.getElementsByClassName("progress-modal")[0].classList.remove("active");
    }

    async function listCameras(){
      let cameraSelect = document.getElementById("select-camera");
      cameras = await cameraEnhancer.getAllCameras();
      for (let index = 0; index < cameras.length; index++) {
        const camera = cameras[index];
        cameraSelect.appendChild(new Option(camera.label,camera.deviceId));
      }
    }

    async function startDetection() {
      await stopDetection();
      cameraViewContainer.style.display = "block";
      let selectedCamera = cameras[document.getElementById("select-camera").selectedIndex];
      let selectedResolution = document.getElementById("select-resolution").selectedOptions[0].value;
      let width = parseInt(selectedResolution.split("x")[0]);
      let height = parseInt(selectedResolution.split("x")[1]);
      await cameraEnhancer.selectCamera(selectedCamera);
      await cameraEnhancer.setResolution({width:width, height:height});
      await cameraEnhancer.open();
      interval = setInterval(processFrame, 100);
    };

    async function stopDetection() {
      clearInterval(interval);
      processing = false;
      await cameraEnhancer.close();
      cameraViewContainer.style.display = "none";
      previousDetectionResults = [];
      drawingLayer.clearDrawingItems();
    };

    async function processFrame(){
      if (processing == true) {
        return;
      }
      processing = true;
      let image = cameraEnhancer.fetchImage();
      let result = await router.capture(image,"DetectDocumentBoundaries_Default");
      console.log(result);
      for (let index = 0; index < result.items.length; index++) {
        const detectionResult = result.items[index];
        if (detectionResult.type ==  Dynamsoft.Core.EnumCapturedResultItemType.CRIT_DETECTED_QUAD) {
          drawOverlay(detectionResult);
          if (steady(detectionResult)) {
            stopDetection();
            appendCroppedFrame(image,detectionResult);
          }
        }
        break;
      }
      processing = false;
    }

    async function appendCroppedFrame(image,detectionResult){
      let normalized = await normalizedImage(image,detectionResult.location.points);
      let viewer = document.getElementById("documentViewer");
      document.getElementById("image").src = normalized.toCanvas().toDataURL();
    }

    async function normalizedImage(image,points){
      let newSettings = await router.getSimplifiedSettings("NormalizeDocument_Default");
      newSettings.roiMeasuredInPercentage = 0;
      newSettings.roi.points = points;
      await router.updateSettings("NormalizeDocument_Default", newSettings);
      let normalizeResult = await router.capture(image, "NormalizeDocument_Default");
      if (normalizeResult.items[0]) {
        return normalizeResult.items[0];
      }else{
        return null;
      }
    }

    function drawOverlay(detectionResult,layer){
      let layerToDraw = layer ?? drawingLayer;
      layerToDraw.clearDrawingItems();
      let quadItem = new Dynamsoft.DCE.QuadDrawingItem(
        {points:detectionResult.location.points}
      );
      layerToDraw.addDrawingItem(quadItem);
    }

    function steady(detectionResult){
      if (previousDetectionResults.length < 5) {
        previousDetectionResults.push(detectionResult);
        return false;
      }else{
        let smallIoU = false;
        for (let i = 0; i < previousDetectionResults.length; i++) {
          if (smallIoU) {
            break;
          }
          const result1 = previousDetectionResults[i];
          for (let j = 0; j < previousDetectionResults.length; j++) {
            if (i == j) {
              continue;
            }
            const result2 = previousDetectionResults[j];
            let iou = intersectionOverUnion(result1.location.points,result2.location.points);
            if (iou < 0.9) {
              smallIoU = true;
              break;
            }
          }
        }
        if (smallIoU) {
          previousDetectionResults.splice(0,1);
          previousDetectionResults.push(detectionResult);
          return false;
        }else{
          return true;
        }
      }
    }
  </script>
</body>
</html>
